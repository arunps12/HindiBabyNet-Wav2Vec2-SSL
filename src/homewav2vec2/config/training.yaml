# SSL Training configuration
base_model: facebook/wav2vec2-base

# Training hyperparameters
crop_sec: 8.0
per_gpu_batch: 2
grad_accum_steps: 8
fp16: true
gradient_checkpointing: true

# --- Epochs / Steps ---
# With ~346 h of audio, effective batch=64, crop=8s:
#   1 effective epoch ≈ 2,400 steps
#   50,000 steps ≈ 20 passes with different random crops
# max_steps takes priority when > 0; set -1 to use num_train_epochs.
num_train_epochs: 25
max_steps: 50000
epoch_multiplier: 10       # each file yields 10 random crops per epoch

learning_rate: 5.0e-5
warmup_ratio: 0.1          # 10% of total steps = ~5,000 warmup steps
warmup_steps: 5000         # fallback if warmup_ratio not used
weight_decay: 0.01
max_grad_norm: 1.0

# Scheduler
lr_scheduler_type: linear

# Logging & saving
logging_steps: 100
save_steps: 2500
save_total_limit: 5
eval_strategy: "no"        # or "steps" if dev set exists

# Dataloader
num_workers: 4

# Directories
output_dir: artifacts/training
checkpoint_dir: artifacts/training/checkpoints
log_dir: artifacts/training/logs

# HF Hub push (overrides from .env)
push_to_hub: false
hub_model_id: null          # filled from .env HF_REPO_ID
hub_private: true
